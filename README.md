# **Week8Table â€“ Embeddings Applications**

| Application Area | Short Description |
|------------------|-------------------|
| **NLP** | Embeddings represent words or sentences as dense vectors capturing meaning and context, enabling tasks like text classification, sentiment analysis, NER, translation, and document similarity. They allow models to understand semantic relationships rather than raw text. |
| **Recommender Systems** | User and item embeddings encode preferences and item attributes from interaction history, allowing the system to find similar users/items and produce personalized recommendations based on vector similarity. |
| **Image & Video Processing** | CNN-based embeddings represent visual content in numerical form, supporting classification, detection, retrieval, and video understanding. They capture spatial or temporal patterns needed for visual tasks. |
| **Anomaly Detection** | Embeddings learn the structure of normal data so deviations appear as anomalies. Useful in fraud detection, intrusion detection, and general outlier spotting where unusual patterns stand out in vector space. |
| **Knowledge Graphs** | Entities and relationships are converted into vectors, enabling efficient similarity checks and supporting tasks like entity linking, link prediction, and graph-based recommendations. |
| **Sequence Modeling** | Embeddings capture context and dependencies within sequences such as text, audio, or time series, enabling tasks like translation, speech recognition, and sequence generation. |
